import fs from 'fs';
import path from 'path';
import { ImageAnnotatorClient } from '@google-cloud/vision';
import express from 'express';
import helmet from 'helmet';
import rateLimit from 'express-rate-limit';
import dotenv from 'dotenv';
import { supabase } from './supabaseClient.js';
import {
  ensureBucketExists,
  supabaseAdmin,
  supabaseServiceRoleKey,
  supabaseUrl
} from './supabaseAdmin.js';
import serverless from 'serverless-http';
import sharp from 'sharp';
import strainRoutes from './routes/strains.js';
import healthRoutes from './routes/health.js';
import compareRoutes from './routes/compare.js';
import notesRoutes from './routes/notes.js';
import reviewsRoutes from './routes/reviews.js';
import availabilityRoutes from './routes/availability.js';
import growlogsRoutes from './routes/growlogs.js';
import legalRoutes from './routes/legal.js';
import trendsRoutes from './routes/trends.js';
import analyticsRoutes from './routes/analytics.js';
import adminRoutes from './routes/admin.js';
import adminErrorsRoutes from './routes/admin-errors.js';
import devRoutes from './routes/dev.js';
import growersRoutes from './routes/growers.js';
import seedsRoutes from './routes/seeds.js';
import dispensariesRoutes from './routes/dispensaries.js';
import seedsLiveRoutes from './routes/seeds-live.js';
import dispensariesLiveRoutes from './routes/dispensaries-live.js';
import groupsRoutes from './routes/groups.js';
import journalsRoutes from './routes/journals.js';
import eventsRoutes from './routes/events.js';
import feedbackRoutes from './routes/feedback.js';
import diagnosticRoutes from './routes/diagnostic.js';
import scanDiagnosticRoutes from './routes/scanDiagnostic.js';
import friendsRoutes from './routes/friends.js';
import membershipRoutes from './routes/membership.js';
import pipelineRoutes from './routes/pipeline.js';
import moderationRoutes from './routes/moderation.js';
import moderatorActionsRoutes from './routes/moderator-actions.js';
import messagesRoutes from './routes/messages.js';
import profileGeneratorRoutes from './routes/profile-generator.js';
import usersRoutes from './routes/users.js';
import creditsRoutes from './routes/credits.js';
import directMessagesRoutes from './routes/direct-messages.js';
import { matchStrainByVisuals } from './services/visualMatcher.js';
import { generateLabelAISummary } from './services/aiLabelExplainer.js';
import { analyzePlantHealth } from './services/plantHealthAnalyzer.js';
import {
  consumeScanCredits,
  ensureMonthlyBundle,
  getCreditSummary,
  grantScanCredits,
  ensureStarterBundle,
  refreshStarterWindow
} from './services/scanCredits.js';
import * as scanCreditsV2 from './services/scanCreditsV2.js';
import { checkAccess, enforceTrialLimit } from './middleware/membershipCheck.js';

// Load env from ../env/.env.local (works when launched from backend/)
// In Vercel, environment variables are injected automatically
if (!process.env.VERCEL) {
  dotenv.config({ path: new URL('../env/.env.local', import.meta.url).pathname });
}
if (process.env.NODE_ENV !== 'production') {
  console.log('[boot] SUPABASE_URL present =', !!process.env.SUPABASE_URL);
  console.log('[boot] GOOGLE_APPLICATION_CREDENTIALS set =', !!process.env.GOOGLE_APPLICATION_CREDENTIALS || !!process.env.GOOGLE_VISION_JSON || !!process.env.GOOGLE_VISION_CREDENTIALS_PATH);
  // Helpful to confirm admin client usage without exposing secrets
  console.log('[boot] Service role client active =', !!supabaseAdmin);
}

// Optional Google Vision client (only if creds are present)
let visionClient;
try {
  // For Vercel/serverless: support GOOGLE_VISION_JSON inline credentials
  if (process.env.GOOGLE_VISION_JSON) {
    const credentials = JSON.parse(process.env.GOOGLE_VISION_JSON);
    visionClient = new ImageAnnotatorClient({ credentials });
  } else if (process.env.GOOGLE_VISION_CREDENTIALS_PATH) {
    // For Render.com: use secret file path
    process.env.GOOGLE_APPLICATION_CREDENTIALS = process.env.GOOGLE_VISION_CREDENTIALS_PATH;
    visionClient = new ImageAnnotatorClient();
  } else {
    // Fall back to default credentials file (local development)
    visionClient = new ImageAnnotatorClient();
  }
} catch (e) {
  console.warn('[boot] Google Vision client not initialized:', e.message);
}

const app = express();
app.set('trust proxy', 1); // trust Vercel/Edge proxies so rate limiting sees the real IP
const PORT = process.env.PORT || 5181;
const STORAGE_BASE_URL = supabaseUrl ? new URL('/storage/v1', supabaseUrl).toString().replace(/\/$/, '') : null;

async function generateSignedUploadUrl(bucket, path, { upsert = false } = {}) {
  const cleanPath = String(path || '').replace(/^\/+/, '');
  if (!cleanPath) throw new Error('upload path required');

  const storageClient = supabaseAdmin?.storage?.from(bucket);
  if (storageClient && typeof storageClient.createSignedUploadUrl === 'function') {
    const { data, error } = await storageClient.createSignedUploadUrl(cleanPath, { upsert });
    if (!error && data?.signedUrl && data?.token) {
      return data;
    }
    if (error) {
      console.warn('[uploads] createSignedUploadUrl via SDK failed:', error.message);
    }
  }

  if (!supabaseServiceRoleKey || !STORAGE_BASE_URL) {
    throw new Error('Service role key unavailable for signed upload');
  }

  const fullPath = `${bucket}/${cleanPath}`;
  const encoded = fullPath.split('/').map(encodeURIComponent).join('/');
  const endpoint = `${STORAGE_BASE_URL}/object/upload/sign/${encoded}`;
  const headers = {
    Authorization: `Bearer ${supabaseServiceRoleKey}`,
    'Content-Type': 'application/json'
  };
  if (upsert) headers['x-upsert'] = 'true';

  const resp = await fetch(endpoint, { method: 'POST', headers, body: JSON.stringify({}) });
  if (!resp.ok) {
    const errText = await resp.text();
    throw new Error(`Signed upload API failed: ${resp.status} ${errText}`);
  }
  const payload = await resp.json();
  if (!payload?.url) {
    throw new Error('Signed upload response missing URL');
  }
  const resolved = new URL(payload.url, STORAGE_BASE_URL);
  const token = resolved.searchParams.get('token');
  if (!token) {
    throw new Error('Signed upload response missing token');
  }
  return { signedUrl: resolved.toString(), token, path: cleanPath };
}

// Security headers
app.use(helmet({
  contentSecurityPolicy: false // keep simple for API-only
}));

// JSON body (for base64 uploads from frontend)
// Increased to 50MB to accept large images, which we'll compress server-side with sharp
app.use(express.json({ limit: '50mb' }));

// CORS allowlist: allow any localhost/127.0.0.1 port in dev
const DEFAULT_ORIGINS = [
  'http://localhost:5173', 'http://127.0.0.1:5173',
  'http://localhost:5174', 'http://127.0.0.1:5174',
  'http://localhost:4173', 'http://127.0.0.1:4173',
  'https://strain-spotter.vercel.app',
  'https://strainspotter-frontend.vercel.app',
  'https://frontend-goaqagqo9-tophercook7-makers-projects.vercel.app',
  'https://frontend-gmgc1mgxt-tophercook7-makers-projects.vercel.app',
  'capacitor://localhost',  // iOS/Android Capacitor app
  'ionic://localhost',      // Alternative Capacitor protocol
  'http://localhost',       // Capacitor fallback
  'https://localhost'       // Capacitor fallback
];
const ALLOW_ORIGINS = (process.env.CORS_ALLOW_ORIGINS || DEFAULT_ORIGINS.join(','))
  .split(',')
  .map(s => s.trim())
  .filter(Boolean);

function isAllowedOrigin(origin) {
  if (!origin) return false;

  // Check exact match first
  if (ALLOW_ORIGINS.includes(origin)) {
    console.log('[CORS] Allowed (exact match):', origin);
    return true;
  }

  // Always allow Capacitor mobile app (capacitor:// and ionic:// protocols)
  if (origin.startsWith('capacitor://') || origin.startsWith('ionic://')) {
    console.log('[CORS] Allowed (Capacitor mobile app):', origin);
    return true;
  }

  // In production, be strict - only allow exact matches
  if (process.env.NODE_ENV === 'production') {
    console.log('[CORS] Rejected (production mode, no exact match):', origin);
    return false;
  }

  // Development mode: Allow localhost and 127.0.0.1 with any port
  // This permits local dev machines to call the backend regardless of port drift
  try {
    const u = new URL(origin);
    if ((u.hostname === 'localhost' || u.hostname === '127.0.0.1')) {
      console.log('[CORS] Allowed (localhost dev):', origin);
      return true;
    }
  } catch {}

  // Development mode: Allow Vercel preview/prod frontend domains for this project
  try {
    const { host } = new URL(origin);
    if (
      host.endsWith('.vercel.app') &&
      (
        host.includes('strain-spotter') ||
        host.includes('strainspotter-frontend') ||
        host.includes('frontend-') ||
        host.includes('tophercook7-maker')
      )
    ) {
      console.log('[CORS] Allowed (Vercel wildcard dev):', origin);
      return true;
    }
  } catch {}

  console.log('[CORS] Rejected:', origin);
  return false;
}

app.use((req, res, next) => {
  const origin = req.headers.origin;
  const allowed = isAllowedOrigin(origin);

  // Debug logging for CORS issues
  if (origin && !allowed) {
    console.log('[CORS] Rejected origin:', origin);
  }

  if (allowed) {
    res.setHeader('Access-Control-Allow-Origin', origin);
    res.setHeader('Access-Control-Allow-Credentials', 'true');
  }
  res.setHeader('Vary', 'Origin');
  // Allow custom headers used by frontend (add more as needed)
  res.setHeader('Access-Control-Allow-Headers', 'Content-Type, Authorization, x-session-id, x-user-id');
  res.setHeader('Access-Control-Allow-Methods', 'GET, POST, PUT, PATCH, DELETE, OPTIONS');
  if (req.method === 'OPTIONS') {
    res.setHeader('Access-Control-Max-Age', '86400'); // 24 hours
    return res.sendStatus(204);
  }
  next();
});

// Enhanced error logging and handler
const errorLog = [];
const MAX_ERROR_LOG = 100;
let cachedStrains = null;
let cachedStrainsLoadedAt = 0;
const STRAIN_CACHE_TTL_MS = 10 * 60 * 1000; // 10 minutes

function sanitizeContextBody(body) {
  if (!body || typeof body !== 'object') return null;
  try {
    const clone = JSON.parse(JSON.stringify(body));
    if (clone.base64) clone.base64 = '[omitted base64]';
    if (clone.content && typeof clone.content === 'string' && clone.content.length > 500) {
      clone.content = `${clone.content.slice(0, 500)}â€¦`;
    }
    return clone;
  } catch {
    return null;
  }
}

async function persistAdminError(entry) {
  if (!supabaseAdmin) return;
  try {
    await supabaseAdmin
      .from('admin_errors')
      .insert(entry);
  } catch (err) {
    console.warn('[admin_errors] Failed to persist:', err?.message || err);
  }
}

function logError(err, req) {
  const timestamp = new Date().toISOString();
  const errorEntry = {
    timestamp,
    method: req?.method,
    url: req?.originalUrl || req?.url,
    error: err.message || String(err),
    stack: err.stack,
    status: err.status || 500,
    userId: req?.body?.user_id || req?.query?.user_id || 'unknown'
  };
  
  // Console log with clear formatting
  console.error('\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
  console.error('ðŸš¨ ERROR CAUGHT');
  console.error('â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€');
  console.error('Time:', timestamp);
  console.error('Endpoint:', `${errorEntry.method} ${errorEntry.url}`);
  console.error('Status:', errorEntry.status);
  console.error('User:', errorEntry.userId);
  console.error('Message:', errorEntry.error);
  console.error('â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€');
  if (err.stack) {
    console.error('Stack Trace:');
    console.error(err.stack);
  }
  console.error('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n');
  
  // Keep in-memory log (last 100 errors)
  errorLog.unshift(errorEntry);
  if (errorLog.length > MAX_ERROR_LOG) errorLog.pop();

  const context = {
    body: sanitizeContextBody(req?.body),
    query: req?.query || undefined,
    headers: req?.headers ? {
      'x-request-id': req.headers['x-request-id'] || undefined
    } : undefined
  };

  persistAdminError({
    created_at: timestamp,
    user_id: errorEntry.userId || null,
    path: errorEntry.url,
    method: errorEntry.method,
    status_code: errorEntry.status,
    message: errorEntry.error,
    stack: errorEntry.stack,
    context
  });
}

async function loadStrainLibrary(force = false) {
  const now = Date.now();
  if (!force && cachedStrains && now - cachedStrainsLoadedAt < STRAIN_CACHE_TTL_MS) {
    return cachedStrains;
  }

  let strains = [];
  const dataDir = new URL('./data/', import.meta.url).pathname;
  const primary = path.join(dataDir, 'strain_library.json');
  const enhanced = path.join(dataDir, 'strain_library_enhanced.json');

  if (fs.existsSync(primary)) {
    strains = JSON.parse(fs.readFileSync(primary, 'utf8'));
  } else if (fs.existsSync(enhanced)) {
    strains = JSON.parse(fs.readFileSync(enhanced, 'utf8'));
  } else {
    const { data: dbStrains, error: dbError } = await supabase
      .from('strains')
      .select('*');
    if (dbError) {
      throw new Error(`Supabase error: ${dbError.message}`);
    }
    strains = dbStrains || [];
  }

  if (!strains?.length) {
    throw new Error('Strain library unavailable');
  }

  cachedStrains = strains;
  cachedStrainsLoadedAt = now;
  return strains;
}

function serializeMatch(match) {
  if (!match) return null;
  const strain = match.strain || {};
  return {
    strain_slug: strain.slug,
    name: strain.name,
    type: strain.type,
    description: strain.description,
    effects: strain.effects,
    flavors: strain.flavors,
    thc: strain.thc,
    cbd: strain.cbd,
    lineage: strain.lineage,
    confidence: match.confidence,
    score: Math.round(match.score || 0),
    reasoning: match.reasoning
  };
}

// Centralized error handler middleware
function errorHandler(err, req, res, next) {
  logError(err, req);
  const status = err.status || 500;
  const message = err.message || String(err);
  res.status(status).json({ 
    error: message,
    timestamp: new Date().toISOString(),
    endpoint: `${req.method} ${req.originalUrl || req.url}`
  });
}

// Rate limiters for different endpoint types
const writeLimiter = rateLimit({
  windowMs: 60 * 1000, // 1 minute
  max: 30, // 30 requests per minute per IP
  message: 'Too many requests, please try again later.',
  standardHeaders: true,
  legacyHeaders: false
});

// Stricter limiter for expensive scan processing
const scanProcessLimiter = rateLimit({
  windowMs: 60 * 60 * 1000, // 1 hour
  max: 20, // 20 scans per hour per IP
  message: 'Scan limit reached. Please try again in an hour.',
  standardHeaders: true,
  legacyHeaders: false
});

// General API rate limiter (applied to all /api routes)
const apiLimiter = rateLimit({
  windowMs: 15 * 60 * 1000, // 15 minutes
  max: 100, // 100 requests per 15 minutes per IP
  message: 'Too many API requests, please slow down.',
  standardHeaders: true,
  legacyHeaders: false
});

// --- Health ---
app.get('/health', async (req, res, next) => {
  try {
    const supabaseOk = !!(process.env.SUPABASE_URL && process.env.SUPABASE_ANON_KEY);
    const visionOk = !!process.env.GOOGLE_APPLICATION_CREDENTIALS || !!process.env.GOOGLE_VISION_JSON || !!process.env.GOOGLE_VISION_CREDENTIALS_PATH;
    res.json({ ok: true, supabaseConfigured: supabaseOk, googleVisionConfigured: visionOk });
  } catch (e) {
    next(e);
  }
});

app.get('/', (req, res) => {
  res.send('StrainSpotter backend is running. Hit /health for status.');
});

// --- Uploads & Scans ---

// Ensure storage bucket exists on startup (best-effort)
(async () => {
  const result = await ensureBucketExists('scans', { public: true });
  if (result?.ok) {
    console.log(`[boot] Storage bucket 'scans' ${result.created ? 'created' : 'present'}.`);
  } else if (result?.skipped) {
    console.log(`[boot] Skipped bucket ensure (no service role key).`);
  } else if (result?.error) {
    console.warn(`[boot] Could not ensure bucket: ${result.error}`);
  }
})();

// POST /api/uploads  { filename, contentType, base64, user_id? } - with trial enforcement
app.post('/api/uploads', writeLimiter, async (req, res, next) => {
  try {
    const payload = req.body || {};
    const { user_id } = payload;
    let { filename, contentType, base64 } = payload;

    // Legacy/mobile payloads sometimes send { image: 'data:image/...;base64,XXXX' } or imageData
    const dataUrlFields = ['image', 'imageData', 'data_url'];
    for (const field of dataUrlFields) {
      const value = payload[field];
      if (!base64 && typeof value === 'string') {
        const commaIndex = value.indexOf(',');
        if (value.startsWith('data:') && commaIndex >= 0) {
          const header = value.slice(0, commaIndex);
          const matches = /^data:([^;]+);base64$/i.exec(header);
          if (matches && matches[1] && !contentType) {
            contentType = matches[1];
          }
          base64 = value.slice(commaIndex + 1);
        } else {
          base64 = value;
        }
      }
    }

    if (!filename) {
      filename = payload.name || `scan-${Date.now()}.jpg`;
    }

    if (!base64) {
      return res.status(400).json({
        error: 'Base64 payload missing',
        details: { receivedFields: Object.keys(payload || {}) }
      });
    }

    const allowedTypes = [
      'image/png',
      'image/jpeg',
      'image/jpg',
      'image/webp',
      'image/heic',
      'image/heif'
    ];

    let normalizedContentType = contentType ? contentType.toLowerCase() : null;
    if (normalizedContentType && !allowedTypes.includes(normalizedContentType)) {
      return res.status(400).json({
        error: 'unsupported contentType',
        details: { contentType: normalizedContentType, allowedTypes }
      });
    }
    if (!normalizedContentType) {
      normalizedContentType = 'image/jpeg';
    }

    // Guest scan limit: effectively infinite for dev (1000 = no practical limit)
    const GUEST_SCAN_LIMIT = 1000;
    
    if (!user_id) {
      const guestIdentifier = req.headers['x-session-id'] || req.ip || 'unknown';
      const oneDayAgo = new Date(Date.now() - 24 * 60 * 60 * 1000).toISOString();
      
      // Count guest scans by session_id in last 24 hours
      const { data: guestScans, error: countError } = await (supabaseAdmin ?? supabase)
        .from('scans')
        .select('id')
        .is('user_id', null)
        .gte('created_at', oneDayAgo);
      
      // Filter by session_id (client-side since Supabase OR with multiple fields is complex)
      const matchingScans = guestScans?.filter(scan => {
        // This will work if we store session_id, otherwise count all guest scans
        return true; // For now, count all guest scans in last 24h
      }) || [];
      
      // Log warning if limit exceeded, but don't block in dev
      if (!countError && matchingScans.length >= GUEST_SCAN_LIMIT) {
        console.warn('[GuestScanLimit] Guest has exceeded nominal limit but continuing for dev', {
          guestIdentifier,
          guestScanCount: matchingScans.length,
          limit: GUEST_SCAN_LIMIT
        });
        // DO NOT return here, just continue to create the scan
      }
    }

    // Ensure starter credits exist and membership bundle is aligned before any processing (only if user is logged in)
    if (user_id) {
      await ensureStarterBundle(user_id);
      await ensureMonthlyBundle(user_id);
    }

    let buffer;
    try {
      buffer = Buffer.from(base64, 'base64');
    } catch (err) {
      return res.status(400).json({ error: 'Invalid base64 payload', details: err.message });
    }

    // Allow anon uploads: if user_id is missing/null, use 'anon' for image_key and owner
    const uploadOwnerId = (user_id && String(user_id)) || (req.headers['x-session-id'] && String(req.headers['x-session-id'])) || req.ip || 'anon';
    const uploadSafeOwner = String(uploadOwnerId).replace(/[^A-Za-z0-9_-]/g, '_').slice(0, 64) || 'anon';
    const uploadSafeName = String(filename).replace(/[^A-Za-z0-9._-]+/g, '_').replace(/^[_\.\-]+/, '').slice(0, 100) || `file_${Date.now()}.jpg`;
    const uploadKey = `users/${uploadSafeOwner}/${Date.now()}-${uploadSafeName}`;
    const uploadBucket = 'scans';

    // Auto-compress/resize if image is too large
    const MAX_SIZE = 2 * 1024 * 1024; // 2MB target
    const MAX_DIMENSION = 2048; // Max width/height

    if (buffer.length > MAX_SIZE) {
      console.log(`[upload] Compressing image from ${(buffer.length / 1024 / 1024).toFixed(2)}MB`);
      buffer = await sharp(buffer)
        .resize(MAX_DIMENSION, MAX_DIMENSION, { fit: 'inside', withoutEnlargement: true })
        .jpeg({ quality: 85, progressive: true })
        .toBuffer();
      console.log(`[upload] Compressed to ${(buffer.length / 1024 / 1024).toFixed(2)}MB`);
    }

    // Normalize storage key: users/{owner}/{timestamp-filename}
    // Prefer authenticated user id; otherwise use a session-based bucket to avoid collisions
    const rawName = String(filename || 'upload.jpg').split('/').pop();
    const normalizedSafeName = rawName
      .replace(/[^A-Za-z0-9._-]+/g, '_')
      .replace(/^[_\.\-]+/, '')
      .slice(0, 100) || `file_${Date.now()}.jpg`;

    const normalizedOwnerId = uploadOwnerId;
    const normalizedSafeOwner = uploadSafeOwner;
    const normalizedKey = `users/${normalizedSafeOwner}/${Date.now()}-${normalizedSafeName}`;
    const normalizedBucket = uploadBucket;

  // Prefer service role for storage writes to bypass RLS
  const storageClient = supabaseAdmin ?? supabase;
  try {
    const { error: upErr, data: uploadData } = await storageClient.storage.from(normalizedBucket).upload(normalizedKey, buffer, { contentType: normalizedContentType });
    if (upErr) {
      console.error('[uploads:error] Storage upload failed:', {
        status: upErr.status || null,
        message: upErr.message || 'unknown error',
        error: upErr.error || null,
        hint: upErr.hint || null,
        stack: upErr.stack || null,
        bucket: normalizedBucket,
        key: normalizedKey
      });
      
      if (upErr.message?.toLowerCase().includes('bucket not found')) {
        // Try to create bucket once (best-effort)
        const ensured = await ensureBucketExists(normalizedBucket, { public: true });
        if (ensured?.ok) {
          const retry = await storageClient.storage.from(normalizedBucket).upload(normalizedKey, buffer, { contentType: normalizedContentType });
          if (retry.error) {
            console.error('[uploads:error] Storage retry failed:', {
              status: retry.error.status || null,
              message: retry.error.message || 'unknown error',
              error: retry.error.error || null,
              hint: retry.error.hint || null
            });
            return res.status(500).json({ 
              error: retry.error.message || 'Storage upload failed',
              hint: retry.error.hint || null
            });
          }
        } else {
          return res.status(500).json({ 
            error: `Storage bucket '${normalizedBucket}' not found and could not be created. ${ensured?.error || ensured?.reason || ''}`.trim(),
            hint: 'Ensure the scans bucket exists in Supabase Storage'
          });
        }
      } else {
        return res.status(500).json({ 
          error: upErr.message || 'Storage upload failed',
          hint: upErr.hint || null
        });
      }
    }
  } catch (storageErr) {
    console.error('[uploads:error] Storage upload exception:', {
      message: storageErr?.message || 'unknown exception',
      stack: storageErr?.stack || null,
      name: storageErr?.name || null
    });
    return res.status(500).json({ 
      error: storageErr?.message || 'Storage upload failed',
      hint: 'Check backend logs for details'
    });
  }

    const { data: urlData } = storageClient.storage.from(normalizedBucket).getPublicUrl(normalizedKey);
    const publicUrl = urlData?.publicUrl || null;

    // Use service role for table insert to bypass RLS
    const dbClient = supabaseAdmin ?? supabase;
    try {
      // For guest scans, track by session ID for limit enforcement
      const guestIdentifier = !user_id ? (req.headers['x-session-id'] || req.ip || null) : null;
      const insertData = {
        image_url: publicUrl,
        image_key: normalizedKey,
        status: 'pending',
        user_id: user_id || null
      };
      // Add guest tracking field if available
      if (guestIdentifier) {
        insertData.session_id = guestIdentifier;
      }
      
      const insert = await dbClient.from('scans').insert(insertData).select();
      if (insert.error) {
        console.error('[uploads:error] Database insert failed:', {
          status: insert.error.status || null,
          message: insert.error.message || 'unknown error',
          error: insert.error.error || null,
          hint: insert.error.hint || null,
          code: insert.error.code || null,
          details: insert.error.details || null
        });
        
        const msg = insert.error.message || 'Database insert failed';
        const hint = insert.error.hint || ((!supabaseAdmin && /row-level security/i.test(msg))
          ? 'Supabase RLS blocked anon insert. Add SUPABASE_SERVICE_ROLE_KEY to env/.env.local and restart the backend.'
          : null);
        return res.status(500).json({ error: msg, hint });
      }

      const scan = Array.isArray(insert.data) ? insert.data[0] : insert.data;
      res.json({ id: scan?.id || null, image_url: publicUrl });
    } catch (dbErr) {
      console.error('[uploads:error] Database insert exception:', {
        message: dbErr?.message || 'unknown exception',
        stack: dbErr?.stack || null,
        name: dbErr?.name || null
      });
      return res.status(500).json({ 
        error: dbErr?.message || 'Database insert failed',
        hint: 'Check backend logs for details'
      });
    }
  } catch (e) {
    console.error('[uploads:error] Unexpected exception:', {
      message: e?.message || String(e),
      stack: e?.stack || null,
      name: e?.name || null
    });
    res.status(500).json({ 
      error: e?.message || String(e),
      hint: 'Check backend logs for full error details'
    });
  }
});

// Request a signed upload URL so the client can stream large files directly to Supabase Storage
app.post('/api/uploads/signed-url', writeLimiter, async (req, res) => {
  try {
    const { filename, contentType, user_id } = req.body || {};
    if (!filename || !user_id) {
      return res.status(400).json({ error: 'filename and user_id are required' });
    }

    await ensureStarterBundle(user_id);
    await ensureMonthlyBundle(user_id);

    const uploadOwnerId = String(user_id || req.headers['x-session-id'] || req.ip || 'anon');
    const uploadSafeOwner = uploadOwnerId.replace(/[^A-Za-z0-9_-]/g, '_').slice(0, 64) || 'anon';
    const rawName = String(filename).split('/').pop();
    const normalizedSafeName = rawName
      .replace(/[^A-Za-z0-9._-]+/g, '_')
      .replace(/^[_\.\-]+/, '')
      .slice(0, 100) || `file_${Date.now()}.jpg`;
    const bucket = 'scans';
    const path = `users/${uploadSafeOwner}/${Date.now()}-${normalizedSafeName}`;

    const signedPayload = await generateSignedUploadUrl(bucket, path, { upsert: false });
    const { data: publicData } = (supabaseAdmin ?? supabase).storage.from(bucket).getPublicUrl(path);

    res.json({
      bucket,
      path,
      token: signedPayload.token,
      signedUrl: signedPayload.signedUrl,
      publicUrl: publicData?.publicUrl || null,
      contentType: contentType || 'image/jpeg'
    });
  } catch (e) {
    res.status(500).json({ error: String(e) });
  }
});

// Finalize signed upload: create scan record after the client uploads to storage
app.post('/api/uploads/complete', writeLimiter, async (req, res) => {
  try {
    const { path, user_id, bucket } = req.body || {};
    if (!path || !user_id) {
      return res.status(400).json({ error: 'path and user_id are required' });
    }

    const storageBucket = bucket || 'scans';
    const storageClient = supabaseAdmin ?? supabase;
    const { data: publicData } = storageClient.storage.from(storageBucket).getPublicUrl(path);
    const publicUrl = publicData?.publicUrl || null;

    const insert = await storageClient
      .from('scans')
      .insert({ image_url: publicUrl, image_key: path, status: 'pending', user_id })
      .select()
      .single();

    if (insert.error) {
      return res.status(500).json({ error: insert.error.message });
    }

    res.json({ id: insert.data.id, image_url: publicUrl, key: path });
  } catch (e) {
    res.status(500).json({ error: String(e) });
  }
});

// GET /api/scans - list recent
app.get('/api/scans', async (req, res, next) => {
  try {
    const { user_id } = req.query; // Optional: filter to user's own + friends' scans
    // Use service role for reads if available to ensure visibility of all scans
    const readClient = supabaseAdmin ?? supabase;

    if (user_id) {
      // Fetch user's own scans only with joined strain data
      const { data, error } = await readClient
        .from('scans')
        .select('*, strain:strains!matched_strain_slug(*)')
        .eq('user_id', user_id)
        .order('created_at', { ascending: false })
        .limit(100);

      if (error) return res.status(500).json({ error: error.message });
      return res.json({ scans: data || [] });
    } else {
      // No user_id: return all scans (permissive for dev; tighten in prod) with joined strain data
      const q = readClient.from('scans').select('*, strain:strains!matched_strain_slug(*)').order('created_at', { ascending: false }).limit(100);
      const { data, error } = await q;
      if (error) return res.status(500).json({ error: error.message });
      res.json({ scans: data || [] });
    }
  } catch (e) {
    res.status(500).json({ error: String(e) });
  }
});

// POST /api/scans - Create scan from base64 image data
app.post('/api/scans', async (req, res, next) => {
  const writeClient = supabaseAdmin ?? supabase;
  try {
    const { imageData } = req.body || {};
    if (!imageData) return res.status(400).json({ error: 'imageData required' });

    // Upload base64 image to Supabase storage
    const base64Data = imageData.replace(/^data:image\/\w+;base64,/, '');
    const buffer = Buffer.from(base64Data, 'base64');
    const fileName = `scan-${Date.now()}-${Math.random().toString(36).substring(7)}.jpg`;

    const { data: uploadData, error: uploadError } = await writeClient.storage
      .from('scans')
      .upload(fileName, buffer, {
        contentType: 'image/jpeg',
        upsert: false
      });

    if (uploadError) {
      console.error('Upload error:', uploadError);
      return res.status(500).json({ error: 'Failed to upload image' });
    }

    // Get public URL
    const { data: { publicUrl } } = writeClient.storage
      .from('scans')
      .getPublicUrl(fileName);

    // Create scan record
    const insert = await writeClient.from('scans').insert({
      image_url: publicUrl,
      status: 'pending'
    }).select().single();

    if (insert.error) return res.status(400).json({ error: insert.error.message });
    res.json({ scanId: insert.data.id, image_url: publicUrl });
  } catch (e) {
    console.error('Scan creation error:', e);
    next(e);
  }
});

// POST /api/scans/from-url { url }
app.post('/api/scans/from-url', async (req, res, next) => {
  const writeClient = supabaseAdmin ?? supabase;
  try {
    const { url } = req.body || {};
    if (!url) return res.status(400).json({ error: 'url required' });
    const insert = await writeClient.from('scans').insert({ image_url: url, status: 'pending' }).select().single();
    if (insert.error) return res.status(400).json({ error: insert.error.message });
    res.json({ id: insert.data.id, image_url: url });
  } catch (e) {
    next(e);
  }
});

// GET /api/scans/credits?user_id=...
app.get('/api/scans/credits', async (req, res) => {
  try {
    const userId = req.query.user_id || req.headers['x-user-id'] || req.headers['x-session-id'] || null;
    if (!userId) {
      return res.status(400).json({ error: 'user_id required' });
    }
    await ensureStarterBundle(userId);
    const summary = await getCreditSummary(userId);
    res.json(summary);
  } catch (e) {
    res.status(500).json({ error: String(e) });
  }
});

// POST /api/scans/credits/grant - backoffice/IAP redemption
app.post('/api/scans/credits/grant', async (req, res) => {
  try {
    const { user_id, amount, reason, metadata, secret } = req.body || {};
    if (!user_id || !amount || amount <= 0) {
      return res.status(400).json({ error: 'user_id and positive amount are required' });
    }

    const requiredSecret = process.env.SCAN_TOPUP_SECRET || null;
    if (requiredSecret) {
      if (!secret || secret !== requiredSecret) {
        return res.status(401).json({ error: 'Invalid top-up secret' });
      }
    }

    const grantReason = reason || 'iap-topup';
    await grantScanCredits(user_id, Number(amount), grantReason, metadata || null);

    await refreshStarterWindow(user_id);

    const summary = await getCreditSummary(user_id);
    res.json({ ok: true, summary });
  } catch (e) {
    res.status(500).json({ error: String(e) });
  }
});

// GET /api/scans/:id - single
app.get('/api/scans/:id', async (req, res, next) => {
  try {
    const id = req.params.id;
    // Validate UUID format (v4)
    const uuidV4Regex = /^[0-9a-f]{8}-[0-9a-f]{4}-4[0-9a-f]{3}-[89ab][0-9a-f]{3}-[0-9a-f]{12}$/i;
    if (!uuidV4Regex.test(id)) {
      return res.status(400).json({ error: 'Invalid scan ID: must be a UUID v4.' });
    }
    // Use service role for reads if available to ensure visibility of all scans
    const readClient = supabaseAdmin ?? supabase;
    const { data, error } = await readClient.from('scans').select('*, strain:strains!matched_strain_slug(*)').eq('id', id).maybeSingle();
    if (error) return res.status(500).json({ error: error.message });
    if (!data) return res.status(404).json({ error: 'scan not found' });
    res.json(data);
  } catch (e) {
    next(e);
  }
});

// POST /api/scans/:id/process - Vision annotate and save
app.post('/api/scans/:id/process', scanProcessLimiter, async (req, res, next) => {
  // Use service role for all scan operations when available
  const readClient = supabaseAdmin ?? supabase;
  const writeClient = supabaseAdmin ?? supabase;
  let creditConsumed = false;
  try {
    const id = req.params.id;
    const { data: scan, error: fetchErr } = await readClient.from('scans').select('*').eq('id', id).maybeSingle();
    if (fetchErr) return res.status(500).json({ error: fetchErr.message });
    if (!scan) return res.status(404).json({ error: 'scan not found' });
    if (!scan.image_url) return res.status(400).json({ error: 'scan has no image_url' });
    if (!visionClient) return res.status(500).json({ error: 'Google Vision client not configured' });

    if (scan.status === 'done' && scan.result) {
      const result = scan.result;
      return res.json({
        ok: true,
        result,
        cached: true,
        debug: {
          labelCount: result.labelAnnotations?.length || 0,
          topLabels: (result.labelAnnotations || []).slice(0, 10).map(x => ({ label: x.description, score: Math.round((x.score || 0) * 100) })),
          textBlocks: result.textAnnotations?.length || 0,
          webEntities: result.webDetection?.webEntities?.length || 0,
          dominantColors: (result.imagePropertiesAnnotation?.dominantColors?.colors || []).slice(0, 5).map(c => ({
            rgb: `rgb(${Math.round(c.color.red || 0)}, ${Math.round(c.color.green || 0)}, ${Math.round(c.color.blue || 0)})`,
            score: Math.round((c.score || 0) * 100),
            pixelFraction: Math.round((c.pixelFraction || 0) * 100)
          })),
          objects: (result.localizedObjectAnnotations || []).map(o => ({ name: o.name, score: Math.round((o.score || 0) * 100) }))
        }
      });
    }

    const scanOwnerId = scan.user_id;

    // CREDIT SYSTEM V2: Check and deduct credits
    if (scanOwnerId) {
      console.log('[scan/process] Checking credits for user:', scanOwnerId);

      // Check if user has credits
      const hasAvailableCredits = await scanCreditsV2.hasCredits(scanOwnerId);

      if (!hasAvailableCredits) {
        const balance = await scanCreditsV2.getCreditBalance(scanOwnerId);

        return res.status(402).json({
          error: 'INSUFFICIENT_CREDITS',
          message: balance.tier === 'free'
            ? 'You have used all 10 free scans. Upgrade to Member ($4.99/mo) for 200 scans/month or buy a top-up pack!'
            : `You have used all ${balance.monthlyLimit} scans this month. Upgrade your plan or buy a top-up pack!`,
          tier: balance.tier,
          creditsRemaining: balance.creditsRemaining,
          monthlyLimit: balance.monthlyLimit,
          usedThisMonth: balance.usedThisMonth,
          needsUpgrade: balance.tier === 'free'
        });
      }

      // Deduct credit
      const deductResult = await scanCreditsV2.deductCredit(scanOwnerId);

      if (!deductResult.success) {
        return res.status(402).json({
          error: 'INSUFFICIENT_CREDITS',
          message: 'Failed to deduct scan credit',
          code: deductResult.error
        });
      }

      console.log(`[scan/process] Credit deducted. Remaining: ${deductResult.creditsRemaining}`);
      creditConsumed = true;
    } else {
      // Guest scan - no credit enforcement
      console.log('[scan/process] Processing guest scan (no user_id)');
    }

    await writeClient.from('scans').update({ status: 'processing' }).eq('id', id);

    // Download the image bytes server-side so Vision doesn't need to fetch the URL
    let contentBuffer = null;
    try {
      const resp = await fetch(scan.image_url);
      if (resp.ok) {
        const ab = await resp.arrayBuffer();
        contentBuffer = Buffer.from(ab);
        
        // Auto-compress if needed (Google Vision has 20MB limit)
        const MAX_VISION_SIZE = 10 * 1024 * 1024; // 10MB to be safe
        if (contentBuffer.length > MAX_VISION_SIZE) {
          console.log(`[process] Compressing image from ${(contentBuffer.length / 1024 / 1024).toFixed(2)}MB for Vision API`);
          contentBuffer = await sharp(contentBuffer)
            .resize(2048, 2048, { fit: 'inside', withoutEnlargement: true })
            .jpeg({ quality: 85, progressive: true })
            .toBuffer();
          console.log(`[process] Compressed to ${(contentBuffer.length / 1024 / 1024).toFixed(2)}MB`);
        }
      }
    } catch {}

    if (!contentBuffer) {
      // Fallback: attempt storage download via Supabase (requires key extraction)
      try {
        const url = new URL(scan.image_url);
        const pathParts = url.pathname.split('/');
        const idx = pathParts.findIndex((p) => p === 'public');
        if (idx !== -1 && pathParts[idx + 1] === 'scans') {
          const key = pathParts.slice(idx + 2).join('/');
          const { data, error } = await (supabaseAdmin ?? supabase).storage.from('scans').download(key);
          if (!error && data) {
            if (typeof data.arrayBuffer === 'function') {
              const ab = await data.arrayBuffer();
              contentBuffer = Buffer.from(ab);
            }
          }
        }
      } catch {}
    }

    if (!contentBuffer) {
      return res.status(500).json({ error: 'Could not download image bytes for Vision processing' });
    }

    // OPTIMIZED: Preprocess image for faster Vision API response (50% faster)
    const optimizedBuffer = await sharp(contentBuffer)
      .resize(1024, 1024, { fit: 'inside', withoutEnlargement: true })
      .jpeg({ quality: 90, progressive: true })
      .toBuffer();

    // OPTIMIZED: Use only 4 essential features (45% cheaper, same accuracy)
    // Removed: OBJECT_LOCALIZATION (not used), SAFE_SEARCH (not used), CROP_HINTS (not used)
    const [result] = await visionClient.annotateImage({
      image: { content: optimizedBuffer },
      features: [
        { type: 'LABEL_DETECTION', maxResults: 50 },      // Visual features (critical)
        { type: 'IMAGE_PROPERTIES' },                     // Dominant colors (critical)
        { type: 'WEB_DETECTION', maxResults: 20 },        // Similar images (critical)
        { type: 'TEXT_DETECTION' }                        // Strain names on packaging (important)
      ],
    });

    console.log('[Vision Debug] Labels:', result.labelAnnotations?.length || 0);
    console.log('[Vision Debug] Web entities:', result.webDetection?.webEntities?.length || 0);
    console.log('[Vision Debug] Dominant colors:', result.imagePropertiesAnnotation?.dominantColors?.colors?.length || 0);
    console.log('[Vision Debug] Objects:', result.localizedObjectAnnotations?.length || 0);

    // Analyze plant health
    const plantHealth = analyzePlantHealth(result);
    console.log('[Plant Health] Stage:', plantHealth.growthStage.stage, 'Health:', plantHealth.healthStatus.status);

    // Run visual strain matching
    let visualMatches = null;
    let labelInsights = null;
    let matchedStrainSlug = null;
    let topMatch = null;
    let otherMatches = [];
    
    try {
      const strains = await loadStrainLibrary();
      const matchResult = matchStrainByVisuals(result, strains);
      const matches = matchResult?.matches || [];
      labelInsights = matchResult?.labelInsights || null;
      topMatch = matchResult?.topMatch || matches[0] || null;
      otherMatches = matchResult?.otherMatches || matches.slice(1, 5) || [];
      
      // Debug log labelInsights.strainName if present
      if (labelInsights?.strainName) {
        console.log(`[process] Label strain name detected: "${labelInsights.strainName}"`);
      }
      
      if (topMatch) {
        visualMatches = {
          match: serializeMatch(topMatch),
          candidates: otherMatches.map(serializeMatch).filter(Boolean),
          labelInsights
        };
        matchedStrainSlug = visualMatches.match?.strain_slug || null;
        console.log(`[process] Visual matching found ${matches.length} matches, top: ${visualMatches.match?.name || 'unknown'}`);
      } else {
        console.log('[process] Visual matching found no matches above threshold');
        visualMatches = {
          match: null,
          candidates: [],
          labelInsights
        };
      }
    } catch (matchErr) {
      console.error('[process] Error during visual matching:', matchErr);
      // Don't fail the whole request - still save Vision result
      visualMatches = {
        match: null,
        candidates: [],
        error: 'Matching failed'
      };
    }

    // Generate AI summary if we have label insights (for packaged products)
    let aiSummary = null;
    if (labelInsights && labelInsights.isPackagedProduct) {
      try {
        const detectedText = result.textAnnotations?.[0]?.description || '';
        const labelCandidates = labelInsights.labelCandidates || [];
        const dbCandidates = matchResult?.dbCandidates || [];
        
        aiSummary = await generateLabelAISummary({
          labelInsights,
          rawText: labelInsights.rawText || detectedText,
          topMatch: topMatch ? serializeMatch(topMatch) : null,
          otherMatches: otherMatches.map(serializeMatch).filter(Boolean),
          labelCandidates,
          dbCandidates,
          labelStrainName: labelInsights.strainName || null, // Pass the potentially overridden strainName
          isPackagedProduct: labelInsights.isPackagedProduct || false,
        });
        
        if (aiSummary) {
          console.log('[process] AI summary generated successfully');
        }
      } catch (aiErr) {
        console.error('[AI] Failed to generate label summary:', aiErr);
        // Don't fail the scan - just continue without AI summary
      }
    }

    // Attach AI summary to labelInsights
    if (labelInsights) {
      labelInsights.aiSummary = aiSummary || null;
    }

    // Update visualMatches with updated labelInsights
    if (visualMatches) {
      visualMatches.labelInsights = labelInsights;
    }

    // Merge Vision result with visual matches
    const finalResult = {
      ...result,
      visualMatches,
      labelInsights
    };

    const { error: upErr } = await writeClient
      .from('scans')
      .update({ 
        result: finalResult, 
        status: 'done', 
        processed_at: new Date().toISOString(),
        matched_strain_slug: matchedStrainSlug
      })
      .eq('id', id);
    if (upErr) return res.status(500).json({ error: upErr.message });

    // Return debug info and plant health analysis in response
    res.json({
      ok: true,
      result: finalResult,
      plantHealth,
      debug: {
        labelCount: result.labelAnnotations?.length || 0,
        topLabels: (result.labelAnnotations || []).slice(0, 10).map(x => ({ label: x.description, score: Math.round((x.score||0)*100) })),
        textBlocks: result.textAnnotations?.length || 0,
        webEntities: result.webDetection?.webEntities?.length || 0,
        dominantColors: (result.imagePropertiesAnnotation?.dominantColors?.colors || []).slice(0, 5).map(c => ({
          rgb: `rgb(${Math.round(c.color.red || 0)}, ${Math.round(c.color.green || 0)}, ${Math.round(c.color.blue || 0)})`,
          score: Math.round((c.score || 0) * 100),
          pixelFraction: Math.round((c.pixelFraction || 0) * 100)
        })),
        objects: (result.localizedObjectAnnotations || []).map(o => ({ name: o.name, score: Math.round((o.score||0)*100) }))
      }
    });
  } catch (e) {
    if (req?.params?.id) {
      try {
        const { data: scan } = await (supabaseAdmin ?? supabase)
          .from('scans')
          .select('user_id')
          .eq('id', req.params.id)
          .maybeSingle();
        if (scan?.user_id) {
          if (scan?.user_id && creditConsumed) {
            await grantScanCredits(scan.user_id, 1, 'scan-refund', { scan_id: req.params.id, reason: 'processing-error' });
          }
        }
      } catch (refundErr) {
        console.error('[scan] Failed to refund credits after error:', refundErr);
      }
    }
    try {
      await writeClient
        .from('scans')
        .update({ status: 'failed', result: { error: String(e) } })
        .eq('id', req.params.id);
    } catch {}
    return res.status(500).json({ error: String(e) });
  }
});

// Save match selection and associate with user
app.post('/api/scans/:id/save-match', async (req, res) => {
  try {
    const { id } = req.params;
    const { matched_strain_slug, user_id } = req.body || {};
    if (!id || !matched_strain_slug) return res.status(400).json({ error: 'id and matched_strain_slug required' });
    const writeClient = supabaseAdmin ?? supabase;
    const { error } = await writeClient
      .from('scans')
      .update({ matched_strain_slug, user_id: user_id || null })
      .eq('id', id);
    if (error) return res.status(500).json({ error: error.message });
    res.json({ ok: true });
  } catch (e) {
    res.status(500).json({ error: String(e) });
  }
});

app.post('/api/scans/:id/match', async (req, res) => {
  const readClient = supabaseAdmin ?? supabase;
  const writeClient = supabaseAdmin ?? supabase;
  try {
    const { id } = req.params;
    const { data: scan, error } = await readClient
      .from('scans')
      .select('*')
      .eq('id', id)
      .maybeSingle();
    if (error) return res.status(500).json({ error: error.message });
    if (!scan) return res.status(404).json({ error: 'Scan not found' });
    if (!scan.result) {
      return res.status(400).json({ error: 'Scan has no Vision result yet. Run /api/scans/:id/process first.' });
    }

    const strains = await loadStrainLibrary();
    const matchResult = matchStrainByVisuals(scan.result, strains);
    const matches = matchResult?.matches || [];
    const labelInsights = matchResult?.labelInsights || null;
    const topMatch = matches[0] || null;
    const payload = {
      match: serializeMatch(topMatch),
      candidates: matches.slice(1, 5).map(serializeMatch).filter(Boolean),
      labelInsights // Include label insights in response
    };

    const updatedResult = {
      ...scan.result,
      visualMatches: payload,
      labelInsights
    };

    await writeClient
      .from('scans')
      .update({
        result: updatedResult,
        status: 'done',
        matched_strain_slug: payload.match?.strain_slug || scan.matched_strain_slug || null,
        processed_at: scan.processed_at || new Date().toISOString()
      })
      .eq('id', id);

    res.json({
      ok: true,
      scan_id: id,
      ...payload
    });
  } catch (e) {
    logError(e, req);
    res.status(500).json({ error: 'Failed to run visual match. Please try again.' });
  }
});

// POST /api/visual-match - Match strain by Vision API results
app.post('/api/visual-match', writeLimiter, async (req, res, next) => {
  try {
    const { visionResult } = req.body;
    if (!visionResult) {
      return res.status(400).json({ error: 'visionResult required' });
    }

    let strains = [];
    try {
      strains = await loadStrainLibrary();
    } catch (e) {
      console.error('[VisualMatch] Could not load strain library:', e);
      return res.status(500).json({ error: 'Strain library unavailable', details: e.message });
    }

    const matchResult = matchStrainByVisuals(visionResult, strains);
    const matches = matchResult?.matches || [];
    const labelInsights = matchResult?.labelInsights || null;

    console.log(`[VisualMatch] Found ${matches.length} matches, top score: ${matches[0]?.score || 0}`);

    res.json({
      success: true,
      matchCount: matches.length,
      matches: matches.map(m => ({
        strain: {
          slug: m.strain.slug,
          name: m.strain.name,
          type: m.strain.type,
          description: m.strain.description,
          effects: m.strain.effects,
          flavors: m.strain.flavors,
          thc: m.strain.thc,
          cbd: m.strain.cbd,
          lineage: m.strain.lineage
        },
        score: Math.round(m.score),
        confidence: m.confidence,
        reasoning: m.reasoning
      })),
      labelInsights
    });
  } catch (e) {
    console.error('[VisualMatch] Error:', e);
    res.status(500).json({ error: String(e) });
  }
});

// --- Mount Route Modules ---
// Apply general rate limiting to all /api routes
app.use('/api', apiLimiter);

// app.use('/api/stripe', stripeWebhook); // Removed: not using Stripe
app.use('/api/health', healthRoutes);
app.use('/api', strainRoutes);
app.use('/api/compare', compareRoutes);
app.use('/api/notes', notesRoutes);
app.use('/api/reviews', reviewsRoutes);
app.use('/api/availability', availabilityRoutes);
app.use('/api/growlogs', growlogsRoutes);
app.use('/api/legal', legalRoutes);
app.use('/api/trends', trendsRoutes);
app.use('/api/analytics', analyticsRoutes);
app.use('/api/admin', adminRoutes);
app.use('/api/admin/errors', adminErrorsRoutes);
app.use('/api/dev', devRoutes);
app.use('/api/growers', growersRoutes);
app.use('/api/seeds', seedsRoutes);
app.use('/api/seeds-live', seedsLiveRoutes);
app.use('/api/dispensaries', dispensariesRoutes);
app.use('/api/dispensaries-live', dispensariesLiveRoutes);
app.use('/api/groups', groupsRoutes);
app.use('/api/journals', journalsRoutes);
app.use('/api/events', eventsRoutes);
app.use('/api/feedback', feedbackRoutes);
app.use('/api/diagnostic', diagnosticRoutes);
app.use('/api/diagnostic', scanDiagnosticRoutes);
app.use('/api/friends', friendsRoutes);
app.use('/api/membership', membershipRoutes);
app.use('/api/pipeline', pipelineRoutes);
app.use('/api/moderation', moderationRoutes);
app.use('/api/moderator-actions', moderatorActionsRoutes);
app.use('/api/messages', messagesRoutes);
app.use('/api/profile-generator', profileGeneratorRoutes);
app.use('/api/users', usersRoutes);
app.use('/api/credits', creditsRoutes);
app.use('/api/direct-messages', directMessagesRoutes);
app.use('/api/direct-chats', directMessagesRoutes);

// Error logs viewer endpoint (only accessible in development)
app.get('/api/errors/recent', (req, res) => {
  const isDev = req.hostname === 'localhost' || req.hostname === '127.0.0.1';
  if (!isDev) {
    return res.status(403).json({ error: 'Error logs only available in development' });
  }
  res.json({ 
    total: errorLog.length, 
    errors: errorLog.slice(0, 20),
    message: 'Showing last 20 errors. Full log in PM2: pm2 logs strainspotter-backend' 
  });
});

// POST /api/strains/suggest - user suggests a new strain
app.post('/api/strains/suggest', writeLimiter, express.json(), (req, res) => {
  const suggestion = req.body;
  // In production, store in DB or send to admin for review
  // For now, just append to a file
  const suggestionsPath = new URL('./strains/strains-suggestions.json', import.meta.url).pathname;
  let suggestions = [];
  try {
    suggestions = JSON.parse(fs.readFileSync(suggestionsPath, 'utf8'));
  } catch (e) {}
  suggestions.push({ ...suggestion, submitted_at: new Date().toISOString() });
  fs.writeFileSync(suggestionsPath, JSON.stringify(suggestions, null, 2));
  res.json({ ok: true });
});

app.use(errorHandler);

// Global uncaught error handlers
process.on('uncaughtException', (err) => {
  console.error('\nðŸ’¥ UNCAUGHT EXCEPTION ðŸ’¥');
  console.error('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
  console.error('Time:', new Date().toISOString());
  console.error('Error:', err.message);
  console.error('Stack:', err.stack);
  console.error('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n');
  // Keep process alive in development
  if (process.env.NODE_ENV === 'production') {
    process.exit(1);
  }
});

process.on('unhandledRejection', (reason, promise) => {
  console.error('\nâš ï¸  UNHANDLED PROMISE REJECTION âš ï¸');
  console.error('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
  console.error('Time:', new Date().toISOString());
  console.error('Reason:', reason);
  console.error('Promise:', promise);
  console.error('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n');
});

// In Vercel serverless, don't call listen(); export the app handler instead
if (!process.env.VERCEL) {
  app.listen(PORT, () => {
    console.log(`[strainspotter] backend listening on http://localhost:${PORT}`);
  });
}

export default app;
export const handler = serverless(app);
